{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import csv\n",
    "import sys \n",
    "import codecs\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replacing excel dates\n",
    "# see: https://stackoverflow.com/questions/14271791/converting-date-formats-python-unusual-date-formats-extract-ymd\n",
    "def get_original_date(column):\n",
    "    match = re.search(r'(\\d{5})', column)\n",
    "    if not match:\n",
    "        return \"\", column\n",
    "    \n",
    "    m = match.group().replace(\" \", \"\").replace(\",\",\"\")\n",
    "    delta = datetime.timedelta(int(m)-2)\n",
    "    date = datetime.date(1900, 1, 1) + delta\n",
    "    date = str(date.strftime(\"%d/%m/%Y\"))\n",
    "    \n",
    "    return str(m), date   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_soup(source):\n",
    "    file = codecs.open(source, 'r')\n",
    "    soup = BeautifulSoup(file.read(), 'html.parser')\n",
    "    file.close()\n",
    "\n",
    "    return soup  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(soup):\n",
    "    ids = re.findall(r\"id\\s*=\\s*\\\"(pf\\w+)\\\"\", str(soup.contents))\n",
    "\n",
    "    lines = {}\n",
    "    for div_id in ids:\n",
    "        pdf_html = soup.find(id=str(div_id))\n",
    "        divs_html = pdf_html.find_all(\"div\", class_=\"c\")\n",
    "\n",
    "        for div in divs_html: \n",
    "            # TODO: error handling\n",
    "            row_id = str(div_id) + \"_\" + div[\"class\"][2]\n",
    "            \n",
    "            if row_id not in lines:\n",
    "                lines[row_id] = list()\n",
    "\n",
    "            lines[row_id].append(str(div.get_text()).strip())\n",
    "\n",
    "    return lines \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lines(lines):\n",
    "    for key, line in lines.items():\n",
    "        if len(line) == 1:\n",
    "            continue\n",
    "\n",
    "        if line[3] not in [\"M\", \"F\"]:\n",
    "            line.insert(2, \"\")\n",
    "\n",
    "        orig_date, new_date = get_original_date(line[5])\n",
    "        line[5] = new_date\n",
    "\n",
    "        line.append(orig_date)\n",
    "\n",
    "        if \"*\" in line[1]:\n",
    "            line[1] = line[1].replace(\"*\", \"\")\n",
    "            line.append(\"*\")\n",
    "        else:\n",
    "            line.append(\"\")\n",
    "            \n",
    "        # converting to uppercase the state and status\n",
    "        line[1] = line[1].upper() # state\n",
    "        line[2] = line[2].upper() # locality\n",
    "        line[6] = line[6].upper() # status\n",
    "        line[7] = line[7].upper() # where they come from\n",
    "        \n",
    "        line.insert(9, \"NO\")\n",
    "        \n",
    "        if \"CONTACTO\" in line[7]:\n",
    "            line[9] = \"SI\"\n",
    "            line[7] = re.sub(r\"CONTACTO(?:\\s*[,/]\\s*)?(.*)\", \"\\\\1\", line[7])\n",
    "        \n",
    "        # converting to uppercase the state\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"results/html/covid-19-resultado-positivos-indre-2020-03-15.html\"\n",
    "destination = \"results/csv/covid-19-resultado-positivos-indre-2020-03-15.csv\"\n",
    "\n",
    "soup = get_soup(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = get_lines(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = fix_lines(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(destination, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"Caso\", \"Estado\", \"Localidad\", \n",
    "            \"Sexo\", \"Edad\", \"FechaInicioSintomas\", \n",
    "            \"Identificacion\", \"Procedencia\", \"FechaLlegada\",\n",
    "            \"Contacto\",\n",
    "            \"FechaInicioSintomasOriginal\", \"Recuperado\"\n",
    "        ]\n",
    "    ) \n",
    "    for key, values in lines.items():\n",
    "        values = [None if x == '' or x == \"NA\" else x for x in values]\n",
    "\n",
    "        if len(values) > 1 and not \"Caso\" in values[0]:\n",
    "            writer.writerow(values) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
